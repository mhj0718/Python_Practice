{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'C:\\\\Users\\\\CPB06GameN\\\\python_code'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['.ipynb_checkpoints',\n",
       " '20210429 1. 파이썬 자료형(숫자, 문자열).ipynb',\n",
       " '20210429 2. 파이썬 자료형(리스트).ipynb',\n",
       " '20210430 1. pandas 모듈 기초.ipynb',\n",
       " '20210430 2.Pandas 활용.ipynb',\n",
       " '20210430 3.Tuple, Dictionary 자료형 등.ipynb',\n",
       " '20210503 1.파이썬 제어문.ipynb',\n",
       " '20210503 2.pandas 데이터 관리.ipynb',\n",
       " '20210504 1.pandas 활용 주차장 예제.ipynb',\n",
       " '20210504 2.공공데이터포탈 활용 및 지도.ipynb',\n",
       " '20210506 1.코로나19 발생 현황 공공데이터 포탈 openAPI 활용.ipynb',\n",
       " '20210506 2.공공데이터 openAPI 예제 실습.ipynb',\n",
       " '20210506 3.네이버 openAPI 뉴스 검색결과 크롤링.ipynb',\n",
       " '20210506 4.openAPI 반복문 사용 예제.ipynb',\n",
       " '20210507 1.네이버 영화 순위 크롤링.ipynb',\n",
       " '20210507 2.네이버 웹툰 순위 크롤링.ipynb',\n",
       " '20210507 3.Bugs 음원차트 1-100위 크롤링.ipynb',\n",
       " '20210507 4.네이버 영화 날짜별 평점 크롤링.ipynb',\n",
       " '20210510 1.네이버 영화 평점 피벗테이블, 평점변동그래프.ipynb',\n",
       " '20210510 2.함수.ipynb',\n",
       " '20210514 1.Selenium 다음카페 크롤링.ipynb',\n",
       " '20210514 2.pandas 판다스 연산.ipynb',\n",
       " '20210514 3.Iframe 사용해 다음카페 크롤링.ipynb',\n",
       " '20210514 4.긍부정 키워드 분석, 워드클라우드.ipynb',\n",
       " '20210514 5.ckonlpy 단어추가.ipynb',\n",
       " '20210525 1. 네이버카페 로그인, 크롤링(모바일 버전).ipynb',\n",
       " '20210525 2. 네이버 카페 크롤링(pc버전) (실패작 수정필요).ipynb',\n",
       " \"20210526 1. 네이버 카페 '기간설정' 크롤링.ipynb\",\n",
       " '20210527 1. YouTube 댓글 크롤링.ipynb',\n",
       " '20210528 1. 네이버 이미지 크롤링 os모듈.ipynb',\n",
       " 'bar 그래프.ipynb',\n",
       " 'review.txt',\n",
       " 'Untitled.ipynb',\n",
       " 'Untitled1.ipynb',\n",
       " '[판다스] 1-1. Pandas 자료구조.ipynb',\n",
       " '[판다스] 2. 데이터입출력(외부파일, 웹 읽어오기).ipynb',\n",
       " '[판다스] 3. 데이터 살펴보기.ipynb',\n",
       " '[판다스] 4-1. matplotlib 시각화.ipynb',\n",
       " '[판다스] 4-2. Seaborn 라이브러리(고급 그래프 도구).ipynb',\n",
       " '[판다스] 5. 데이터 사전 처리.ipynb',\n",
       " '구글스토어 티빙 리뷰 모음.ipynb',\n",
       " '네이버 멤버쉽 단어 빈도 파이차트.ipynb',\n",
       " '넷플릭스 네이버 블로그 크롤링.ipynb',\n",
       " '앱 관련 긍부정, 주요 단어 빈도수 분석.ipynb',\n",
       " '웨이브 전체 전처리 및 긍부정 분석.ipynb',\n",
       " '집콕 정주행 코로나 이전 워드클라우드.ipynb',\n",
       " '집콕 정주행 코로나 이후 워드클라우드.ipynb',\n",
       " '집콕 정주행 키워드 코로나 전.ipynb',\n",
       " '집콕 정주행 키워드 코로나 후.ipynb',\n",
       " '코로나 이전 집콕 정주행 데이터모음.ipynb',\n",
       " '코로나 이후 집콕 정주행 데이터모음.ipynb',\n",
       " '티빙 네이버 블로그 크롤링 단어 분석, 긍부정.ipynb',\n",
       " '티빙 네이버,다음 카페 크롤링 전처리.ipynb',\n",
       " '티빙 전처리 데이터 모음.ipynb',\n",
       " '티빙 전체 전처리 및 긍부정 분석.ipynb',\n",
       " '티빙 크롤링.ipynb',\n",
       " '티빙 트위터 크롤링 전처리.ipynb']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.listdir()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['2021-05-10-2021-05-26초코네이버 카페 크롤링.csv',\n",
       " '20210507 네이버영화 순위.csv',\n",
       " '20210507 네이버웹툰 순위.csv',\n",
       " '20210507 벅스음원순위 1-100.csv',\n",
       " '20210512 2.워드클라우드.ipynb',\n",
       " 'auto-mpg.csv',\n",
       " 'bad.jpg',\n",
       " 'car_in_seoul.xls',\n",
       " 'CCTV_in_Seoul.csv',\n",
       " 'chromedriver.exe',\n",
       " 'chromedriver_win32.zip',\n",
       " 'cloud_83969.png',\n",
       " 'df.ExcelWriter.xlsx',\n",
       " 'df_sample.csv',\n",
       " 'df_sample.json',\n",
       " 'good.jpg',\n",
       " 'logo-python.jpg',\n",
       " 'maptest.html',\n",
       " 'maptest2.html',\n",
       " 'par_in_seoul.xls',\n",
       " 'population_in_Seoul.csv',\n",
       " 'read_csv_sample.csv',\n",
       " 'sample.csv',\n",
       " 'sample.html',\n",
       " 'sample_ko.csv',\n",
       " 'scatter.png',\n",
       " 'scatter_transparent.png',\n",
       " 'SentiWord_info.json',\n",
       " 'stock-data.csv',\n",
       " 'TV.jpg',\n",
       " '[판다스] 4-1. matplotlib.html',\n",
       " '경기도 인구지도.html',\n",
       " '경기도인구데이터.xlsx',\n",
       " '경기도행정구역경계.json',\n",
       " '남북한발전전력량.xlsx',\n",
       " '네이버 영화평점 크롤링.csv',\n",
       " '네이버 카페애플페이셀리니움 크롤링 저장.csv',\n",
       " '네이버openAPI뉴스어버이날저장.csv',\n",
       " '네이버openAPI뉴스저스틴 비버저장.csv',\n",
       " '네이버openAPI뉴스코레일저장.csv',\n",
       " '네이버영화 평점 크롤링.csv',\n",
       " '네이버오픈api_test.csv',\n",
       " '네이버오픈api어버이날저장(중복제거).csv',\n",
       " '네이버오픈api역내 사고저장(중복제거).csv',\n",
       " '네이버오픈api저스틴 비버저장(중복제거).csv',\n",
       " '네이버오픈api코레일저장(중복제거).csv',\n",
       " '다음카페+%EA%B0%95%EC%95%84%EC%A7%80iframe 크롤링 저장.csv',\n",
       " '다음카페+%EA%B0%9C%EB%83%A5%EC%9D%B4iframe 크롤링 저장.csv',\n",
       " '벅스뮤직 1-100 순위 범위설정 크롤링.csv',\n",
       " '서울지역 대학교 위치.xlsx',\n",
       " '서울특별시 내 대학교 위치.html',\n",
       " '서울특별시 내 대학교 위치1.html',\n",
       " '시도별 전출입 인구수.xlsx',\n",
       " '잠백이 헬스카페 보충제 크롤링.csv',\n",
       " '잠백이 헬스카페 크롤링.csv',\n",
       " '전국문화축제표준데이터.csv',\n",
       " '티빙 네이버 크롤링.csv',\n",
       " '파이썬지식인 크롤링.csv']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.listdir('c:/py_data/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import urllib.request\n",
    "from bs4 import BeautifulSoup\n",
    "from selenium import webdriver\n",
    "from tqdm import tqdm\n",
    "import time\n",
    "import os\n",
    "import shutil   # pip install shutil\n",
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "검색어를 입력하세요: 농구공\n",
      "스크롤 다운 횟수를 입력해 주세요(최대6): 6\n"
     ]
    }
   ],
   "source": [
    "keyword = input('검색어를 입력하세요: ')\n",
    "count_down = int(input('스크롤 다운 횟수를 입력해 주세요(최대6): '))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "driver = webdriver.Chrome('c:/py_data/chromedriver.exe')\n",
    "url = 'https://search.naver.com/search.naver?where=image&sm=tab_jum&query='\n",
    "driver.get(url+keyword)\n",
    "time.sleep(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_url_lst = []\n",
    "\n",
    "for count in range(count_down):\n",
    "    driver.execute_script('window.scrollTo(0, document.body.scrollHeight);')\n",
    "    time.sleep(2)\n",
    "    # 크롬드라이버가 열어 놓은 html문서 소스 가지고 온 후 'html.parser'\n",
    "    \n",
    "html = driver.page_source\n",
    "soup = BeautifulSoup(html, 'html.parser')\n",
    "\n",
    "tag_img = soup.find_all('div', class_='thumb')\n",
    "for url_num in tag_img:\n",
    "    img_url_lst.append(url_num.find('img')['src'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "485"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(img_url_lst)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "98"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 중복 url 제거\n",
    "img_url_lst = list(set(img_url_lst))\n",
    "len(img_url_lst)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# img_url_lst에 있는 url들에 접속하여 이미지 저장\n",
    "fdir = 'c:/py_data/'\n",
    "gen_fname = keyword + '_네이버이미지크롤링' "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.makedirs(fdir+gen_fname)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "동일한 이름의 폴더가 있습니다. 삭제 할까요>[y/n]y\n"
     ]
    }
   ],
   "source": [
    "# 저장 디렉토리 만들기\n",
    "list_dir = os.listdir(fdir)\n",
    "for fname in list_dir:\n",
    "    if gen_fname == fname:\n",
    "        ck = input('동일한 이름의 폴더가 있습니다. 삭제 할까요>[y/n]')\n",
    "        if ck == 'y' or ck =='ㅛ':\n",
    "            shutil.rmtree(fdir+gen_fname)\n",
    "        elif ck =='n' or ck == 'ㅜ':\n",
    "            gen_frame = input('새로 생성할 폴더 이름을 입력하세요: ')\n",
    "        else:\n",
    "            print('잘못 누르셨습니다.')\n",
    "            print('프로그램을 종료합니다.')\n",
    "            driver.close()\n",
    "            sys.exit()\n",
    "try:\n",
    "    os.makedirs(fdir+gen_fname)\n",
    "except FileExistsError:\n",
    "    gen_fname = input('동일한 폴더명이 있습니다 새로 입력해 주세요: ')\n",
    "    os.makedirs(fdir+gen_fname)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('c:/py_data/농구공테스트.jpg', <http.client.HTTPMessage at 0x1dd00782640>)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "urllib.request.urlretrieve(img_url_lst[0], 'c:/py_data/농구공테스트.jpg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "img saving...: 100%|██████████| 98/98 [00:06<00:00, 14.08it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "완료 총 98 개의 이미지를 저장했습니다.\n"
     ]
    }
   ],
   "source": [
    "i = 0\n",
    "for img_url in tqdm(img_url_lst, desc='img saving...'):\n",
    "    # URL내용 저장: urllib.request.urlretrieve('url주소', '파일경로.확장자')\n",
    "    img_name = fdir + gen_fname + '/' + keyword + str(i) + '.jpg'\n",
    "    urllib.request.urlretrieve(img_url, img_name)\n",
    "    i += 1\n",
    "driver.close()\n",
    "print('완료 총',len(img_url_lst),'개의 이미지를 저장했습니다.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "검색어를 입력하세요: 짜장면\n",
      "스크롤 다운 횟수를 입력해 주세요(최대6): 6\n",
      "동일한 이름의 폴더가 있습니다. 삭제 할까요>[y/n]ㅛ\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "img saving...: 100%|██████████| 111/111 [00:07<00:00, 13.88it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "완료 총 111 개의 이미지를 저장했습니다.\n"
     ]
    }
   ],
   "source": [
    "import urllib.request\n",
    "from bs4 import BeautifulSoup\n",
    "from selenium import webdriver\n",
    "from tqdm import tqdm\n",
    "import time\n",
    "import os\n",
    "import shutil   # pip install shutil\n",
    "import sys\n",
    "\n",
    "keyword = input('검색어를 입력하세요: ')\n",
    "count_down = int(input('스크롤 다운 횟수를 입력해 주세요(최대6): '))\n",
    "\n",
    "driver = webdriver.Chrome('c:/py_data/chromedriver.exe')\n",
    "url = 'https://search.naver.com/search.naver?where=image&sm=tab_jum&query='\n",
    "driver.get(url+keyword)\n",
    "time.sleep(2)\n",
    "\n",
    "\n",
    "img_url_lst = []\n",
    "\n",
    "for count in range(count_down):\n",
    "    driver.execute_script('window.scrollTo(0, document.body.scrollHeight);')\n",
    "    time.sleep(2)\n",
    "    # 크롬드라이버가 열어 놓은 html문서 소스 가지고 온 후 'html.parser'\n",
    "    \n",
    "html = driver.page_source\n",
    "soup = BeautifulSoup(html, 'html.parser')\n",
    "\n",
    "tag_img = soup.find_all('div', class_='thumb')\n",
    "for url_num in tag_img:\n",
    "    img_url_lst.append(url_num.find('img')['src'])\n",
    "    \n",
    "    \n",
    "# 중복 url 제거\n",
    "img_url_lst = list(set(img_url_lst))\n",
    "len(img_url_lst)\n",
    "\n",
    "# img_url_lst에 있는 url들에 접속하여 이미지 저장\n",
    "fdir = 'c:/py_data/'\n",
    "gen_fname = keyword + '_네이버이미지크롤링' \n",
    "\n",
    "# 저장 디렉토리 만들기\n",
    "list_dir = os.listdir(fdir)\n",
    "for fname in list_dir:\n",
    "    if gen_fname == fname:\n",
    "        ck = input('동일한 이름의 폴더가 있습니다. 삭제 할까요>[y/n]')\n",
    "        if ck == 'y' or ck =='ㅛ':\n",
    "            shutil.rmtree(fdir+gen_fname)\n",
    "        elif ck =='n' or ck == 'ㅜ':\n",
    "            gen_frame = input('새로 생성할 폴더 이름을 입력하세요: ')\n",
    "        else:\n",
    "            print('잘못 누르셨습니다.')\n",
    "            print('프로그램을 종료합니다.')\n",
    "            driver.close()\n",
    "            sys.exit()\n",
    "try:\n",
    "    os.makedirs(fdir+gen_fname)\n",
    "except FileExistsError:\n",
    "    gen_fname = input('동일한 폴더명이 있습니다 새로 입력해 주세요: ')\n",
    "    os.makedirs(fdir+gen_fname)\n",
    "    \n",
    "i = 0\n",
    "for img_url in tqdm(img_url_lst, desc='img saving...'):\n",
    "    # URL내용 저장: urllib.request.urlretrieve('url주소', '파일경로.확장자')\n",
    "    img_name = fdir + gen_fname + '/' + keyword + str(i) + '.jpg'\n",
    "    urllib.request.urlretrieve(img_url, img_name)\n",
    "    i += 1\n",
    "driver.close()\n",
    "print('완료 총',len(img_url_lst),'개의 이미지를 저장했습니다.')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
